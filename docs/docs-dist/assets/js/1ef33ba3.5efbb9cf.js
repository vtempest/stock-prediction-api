"use strict";(self.webpackChunkdocusaurus_openapi_typedoc=self.webpackChunkdocusaurus_openapi_typedoc||[]).push([["651"],{5586:function(e,t,r){r.r(t),r.d(t,{frontMatter:()=>a,default:()=>h,toc:()=>d,metadata:()=>n,assets:()=>o,contentTitle:()=>i});var n=JSON.parse('{"id":"research/XGBoost Params","title":"XGBoost Params","description":"Summary of the Best XGBoost Parameters","source":"@site/docs/research/XGBoost Params.md","sourceDirName":"research","slug":"/research/XGBoost Params","permalink":"/research/XGBoost Params","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"default","previous":{"title":"Weighted Ensemble Improvements","permalink":"/research/Weighted_Ensemble_Improvements"}}'),s=r(5893),l=r(65);let a={},i=void 0,o={},d=[{value:"Summary of the Best XGBoost Parameters",id:"summary-of-the-best-xgboost-parameters",level:2},{value:"Example of Good XGBoost Parameters",id:"example-of-good-xgboost-parameters",level:2},{value:"Why These Parameters Work Well",id:"why-these-parameters-work-well",level:3},{value:"Additional Notes",id:"additional-notes",level:3},{value:"Typical Ranges for Key Parameters",id:"typical-ranges-for-key-parameters",level:3},{value:"References to Documentation",id:"references-to-documentation",level:3}];function c(e){let t={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",section:"section",strong:"strong",sup:"sup",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h2,{id:"summary-of-the-best-xgboost-parameters",children:"Summary of the Best XGBoost Parameters"}),"\n",(0,s.jsx)(t.p,{children:"XGBoost offers a wide array of parameters, which can be grouped into three main categories: general parameters, booster parameters, and learning task parameters. Below is a structured summary of the most important and commonly tuned parameters for optimal model performance."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"General Parameters"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"booster"}),": Type of model to run at each iteration. Options are ",(0,s.jsx)(t.code,{children:"gbtree"})," (default), ",(0,s.jsx)(t.code,{children:"gblinear"}),", or ",(0,s.jsx)(t.code,{children:"dart"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"device"}),": Specify computation device (",(0,s.jsx)(t.code,{children:"cpu"})," or ",(0,s.jsx)(t.code,{children:"cuda"})," for GPU acceleration)."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"verbosity"}),": Controls the amount of messages printed. Range: 0 (silent) to 3 (debug)."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"nthread"}),": Number of parallel threads used for running XGBoost."]}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsxs)(t.strong,{children:["Tree Booster Parameters (for ",(0,s.jsx)(t.code,{children:"gbtree"})," and ",(0,s.jsx)(t.code,{children:"dart"}),")"]})}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Parameter"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Default"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Description"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Typical Range"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"eta (learning_rate)"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0.3"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Step size shrinkage to prevent overfitting. Lower values make learning slower but safer."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"[0.01, 0.3]"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"gamma"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Minimum loss reduction required to make a split. Higher values make the algorithm more conservative."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"[0, \u221E)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"max_depth"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"6"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Maximum depth of a tree. Larger values increase model complexity and risk of overfitting."}),(0,s.jsx)(t.td,{style:{textAlign:"left"}})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"min_child_weight"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Minimum sum of instance weight (hessian) in a child. Higher values make the algorithm more conservative."}),(0,s.jsx)(t.td,{style:{textAlign:"left"}})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"subsample"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Fraction of training samples used per tree. Reduces overfitting."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"(0.5, 1]"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"colsample_bytree"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Fraction of features used per tree."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"(0.5, 1]"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"colsample_bylevel"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Fraction of features used per tree level."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"(0.5, 1]"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"colsample_bynode"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Fraction of features used per split."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"(0.5, 1]"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"lambda (reg_lambda)"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"L2 regularization term on weights."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"[0, \u221E)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"alpha (reg_alpha)"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"L1 regularization term on weights."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"[0, \u221E)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"tree_method"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"auto"}),(0,s.jsxs)(t.td,{style:{textAlign:"left"},children:["Algorithm for constructing trees: ",(0,s.jsx)(t.code,{children:"auto"}),", ",(0,s.jsx)(t.code,{children:"exact"}),", ",(0,s.jsx)(t.code,{children:"approx"}),", ",(0,s.jsx)(t.code,{children:"hist"}),", ",(0,s.jsx)(t.code,{children:"gpu_hist"}),"."]}),(0,s.jsx)(t.td,{style:{textAlign:"left"}})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"scale_pos_weight"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Controls balance of positive/negative weights for unbalanced classification."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"[1, #neg/#pos]"})]})]})]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Learning Task Parameters"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"objective"}),": Specifies the learning task (e.g., ",(0,s.jsx)(t.code,{children:"reg:squarederror"})," for regression, ",(0,s.jsx)(t.code,{children:"binary:logistic"})," for binary classification, ",(0,s.jsx)(t.code,{children:"multi:softmax"})," for multiclass)."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"eval_metric"}),": Evaluation metric for validation data (e.g., ",(0,s.jsx)(t.code,{children:"rmse"}),", ",(0,s.jsx)(t.code,{children:"logloss"}),", ",(0,s.jsx)(t.code,{children:"auc"}),")."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"seed"}),": Random seed for reproducibility."]}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Specialized Parameters"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"DART Booster"}),": Parameters like ",(0,s.jsx)(t.code,{children:"rate_drop"}),", ",(0,s.jsx)(t.code,{children:"skip_drop"}),", and ",(0,s.jsx)(t.code,{children:"sample_type"})," control dropout behavior in the DART booster."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"gblinear Booster"}),": Parameters like ",(0,s.jsx)(t.code,{children:"updater"}),", ",(0,s.jsx)(t.code,{children:"feature_selector"}),", and ",(0,s.jsx)(t.code,{children:"top_k"})," control linear model fitting."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Categorical Features"}),": Parameters such as ",(0,s.jsx)(t.code,{children:"max_cat_to_onehot"})," and ",(0,s.jsx)(t.code,{children:"max_cat_threshold"})," manage categorical data handling."]}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Parameter Tuning Tips"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Start with default values and tune the following for best results:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"max_depth"}),", ",(0,s.jsx)(t.code,{children:"min_child_weight"})," (model complexity)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"subsample"}),", ",(0,s.jsx)(t.code,{children:"colsample_bytree"})," (overfitting control)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"eta"})," (learning rate; lower values often require more boosting rounds)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"gamma"}),", ",(0,s.jsx)(t.code,{children:"lambda"}),", ",(0,s.jsx)(t.code,{children:"alpha"})," (regularization)"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["For imbalanced datasets, adjust ",(0,s.jsx)(t.code,{children:"scale_pos_weight"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["Use ",(0,s.jsx)(t.code,{children:"tree_method=hist"})," or ",(0,s.jsx)(t.code,{children:"gpu_hist"})," for large datasets or GPU acceleration."]}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"example-of-good-xgboost-parameters",children:"Example of Good XGBoost Parameters"}),"\n",(0,s.jsxs)(t.p,{children:["Your provided parameter set is well-constructed for advanced regression tasks, especially with large datasets or when you want to control tree complexity using the number of leaves rather than depth. Here\u2019s an annotated example, with explanations and minor suggestions for further tuning based on best practices and XGBoost documentation[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-3",id:"user-content-fnref-3","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"2"})}),(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-4",id:"user-content-fnref-4","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"3"})}),(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-5",id:"user-content-fnref-5","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"4"})}),":"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-javascript",children:"var xgbParams = {\n  verbosity: 0,                      // Silent logging\n  objective: 'reg:squarederror',     // Standard for regression\n  nthread: 4,                        // Use 4 CPU threads\n  colsample_bytree: 0.85,            // Use 85% of features per tree\n  colsample_bylevel: 0.85,           // Use 85% of features per tree level\n  alpha: 0.05,                       // L1 regularization (encourages sparsity)\n  lambda: 1.2,                       // L2 regularization (prevents overfitting)\n  early_stopping_rounds: 75,         // Stop if no improvement after 75 rounds\n  seed: 42,                          // For reproducibility\n  nrounds: 2500,                     // Max number of boosting rounds\n  tree_method: 'approx',             // Fast approximate tree building\n  grow_policy: 'lossguide',          // Grow trees by loss reduction, not depth\n  max_depth: 0,                      // Unlimited depth (used with lossguide)\n  max_leaves: 64,                    // Limit number of leaves per tree\n  eta: 0.25,                         // Learning rate (lower for more conservative learning)\n  gamma: 0,                          // Minimum loss reduction for split (0 = no constraint)\n  min_child_weight: 1,               // Minimum sum hessian in a child (default, can increase for more conservative splits)\n  subsample: 0.95                    // Use 95% of data per tree (helps prevent overfitting)\n};\n"})}),"\n",(0,s.jsx)(t.h3,{id:"why-these-parameters-work-well",children:"Why These Parameters Work Well"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"colsample_bytree/colsample_bylevel"}),": Subsampling features helps reduce overfitting, especially in high-dimensional data[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-2","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"alpha/lambda"}),": Regularization terms are crucial for controlling model complexity and preventing overfitting, especially with many trees or deep trees[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-3","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-4",id:"user-content-fnref-4-2","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"3"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"tree_method: 'approx' & grow_policy: 'lossguide'"}),": This combination enables efficient training on large datasets, and ",(0,s.jsx)(t.code,{children:"lossguide"})," allows you to control complexity via ",(0,s.jsx)(t.code,{children:"max_leaves"})," instead of ",(0,s.jsx)(t.code,{children:"max_depth"}),"[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-3",id:"user-content-fnref-3-2","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"2"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"max_leaves"}),": Directly limits the number of terminal nodes, which is effective for large or sparse datasets[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-3",id:"user-content-fnref-3-3","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"2"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"eta"}),": A moderate learning rate of 0.25 is a reasonable starting point; you can lower it (e.g., 0.05\u20130.1) for more conservative learning and increase ",(0,s.jsx)(t.code,{children:"nrounds"})," if needed",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-5",id:"user-content-fnref-5-2","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"4"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"subsample"}),": High subsampling (0.95) allows nearly all data to be used but still adds some randomness for regularization[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-4","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"early_stopping_rounds"}),": Prevents unnecessary training if validation error stops improving[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-5","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),"."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"additional-notes",children:"Additional Notes"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["If your dataset is very large or you have access to a GPU, consider using ",(0,s.jsx)(t.code,{children:"tree_method: 'hist'"})," or ",(0,s.jsx)(t.code,{children:"'gpu_hist'"})," for further speedup[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-6","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["For imbalanced regression or classification, you might also want to tune ",(0,s.jsx)(t.code,{children:"scale_pos_weight"}),"[^1]",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-2",id:"user-content-fnref-2-7","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),"."]}),"\n",(0,s.jsx)(t.li,{children:"For time series or weather-energy modeling, these parameters are a strong starting point, but always validate with cross-validation or a hold-out set[^12][^13]."}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"typical-ranges-for-key-parameters",children:"Typical Ranges for Key Parameters"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Parameter"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Typical Range"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"eta"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0.01 \u2013 0.3"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"max_leaves"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"16 \u2013 256"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"colsample_bytree"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0.5 \u2013 1.0"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"subsample"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0.5 \u2013 1.0"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"alpha/lambda"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"0 \u2013 10"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"min_child_weight"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"1 \u2013 10"})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"references-to-documentation",children:"References to Documentation"}),"\n","\n",(0,s.jsxs)(t.section,{"data-footnotes":!0,className:"footnotes",children:[(0,s.jsx)(t.h2,{className:"sr-only",id:"footnote-label",children:"Footnotes"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{id:"user-content-fn-2",children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://xgboost.readthedocs.io/en/stable/parameter.html",children:"https://xgboost.readthedocs.io/en/stable/parameter.html"})," ",(0,s.jsx)(t.a,{href:"#user-content-fnref-2","data-footnote-backref":"","aria-label":"Back to reference 1",className:"data-footnote-backref",children:"\u21A9"})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-2","data-footnote-backref":"","aria-label":"Back to reference 1-2",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"2"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-3","data-footnote-backref":"","aria-label":"Back to reference 1-3",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"3"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-4","data-footnote-backref":"","aria-label":"Back to reference 1-4",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"4"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-5","data-footnote-backref":"","aria-label":"Back to reference 1-5",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"5"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-6","data-footnote-backref":"","aria-label":"Back to reference 1-6",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"6"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-2-7","data-footnote-backref":"","aria-label":"Back to reference 1-7",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"7"})]})]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{id:"user-content-fn-3",children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://xgboosting.com/configure-xgboost-grow_policy-parameter/",children:"https://xgboosting.com/configure-xgboost-grow_policy-parameter/"})," ",(0,s.jsx)(t.a,{href:"#user-content-fnref-3","data-footnote-backref":"","aria-label":"Back to reference 2",className:"data-footnote-backref",children:"\u21A9"})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-3-2","data-footnote-backref":"","aria-label":"Back to reference 2-2",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"2"})]})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-3-3","data-footnote-backref":"","aria-label":"Back to reference 2-3",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"3"})]})]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{id:"user-content-fn-4",children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://datascience.stackexchange.com/questions/108233/recommendations-for-tuning-xgboost-hyperparams",children:"https://datascience.stackexchange.com/questions/108233/recommendations-for-tuning-xgboost-hyperparams"})," ",(0,s.jsx)(t.a,{href:"#user-content-fnref-4","data-footnote-backref":"","aria-label":"Back to reference 3",className:"data-footnote-backref",children:"\u21A9"})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-4-2","data-footnote-backref":"","aria-label":"Back to reference 3-2",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"2"})]})]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{id:"user-content-fn-5",children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://www.machinelearningmastery.com/xgboost-for-regression/",children:"https://www.machinelearningmastery.com/xgboost-for-regression/"})," ",(0,s.jsx)(t.a,{href:"#user-content-fnref-5","data-footnote-backref":"","aria-label":"Back to reference 4",className:"data-footnote-backref",children:"\u21A9"})," ",(0,s.jsxs)(t.a,{href:"#user-content-fnref-5-2","data-footnote-backref":"","aria-label":"Back to reference 4-2",className:"data-footnote-backref",children:["\u21A9",(0,s.jsx)(t.sup,{children:"2"})]})]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){let{wrapper:t}={...(0,l.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},65:function(e,t,r){r.d(t,{Z:()=>i,a:()=>a});var n=r(7294);let s={},l=n.createContext(s);function a(e){let t=n.useContext(l);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),n.createElement(l.Provider,{value:t},e.children)}}}]);